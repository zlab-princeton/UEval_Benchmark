<!DOCTYPE html><!--cJ2AMD_FyXA9wZjgwrnSX--><html lang="en" class="__className_370cd6 __variable_3b6218"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/UEval/_next/static/media/66f30814ff6d7cdf.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/UEval/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/UEval/_next/static/css/5a9dae0d910ab8e0.css" data-precedence="next"/><link rel="stylesheet" href="/UEval/_next/static/css/f0b4f6c31c32f4c0.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/UEval/_next/static/chunks/webpack-a09365ebe8d26123.js"/><script src="/UEval/_next/static/chunks/4bd1b696-100b9d70ed4e49c1.js" async=""></script><script src="/UEval/_next/static/chunks/1255-17599186e8e9f1dd.js" async=""></script><script src="/UEval/_next/static/chunks/main-app-68aeb2d7571af39f.js" async=""></script><script src="/UEval/_next/static/chunks/2619-6e4b0f7a5e306a67.js" async=""></script><script src="/UEval/_next/static/chunks/8720-84a9ef373a7f70f3.js" async=""></script><script src="/UEval/_next/static/chunks/3131-b09b0f545be46bfd.js" async=""></script><script src="/UEval/_next/static/chunks/app/layout-1cb9fbcc639ea8d3.js" async=""></script><script src="/UEval/_next/static/chunks/5707-3ed4755c3efe5d6d.js" async=""></script><script src="/UEval/_next/static/chunks/app/error-ae7bc8cfe55bb9bb.js" async=""></script><script src="/UEval/_next/static/chunks/2906-d3accac85286ef3a.js" async=""></script><script src="/UEval/_next/static/chunks/4127-d7e3f6c805caa2e3.js" async=""></script><script src="/UEval/_next/static/chunks/7712-4cbad2349309b180.js" async=""></script><script src="/UEval/_next/static/chunks/2659-581a7e9225987806.js" async=""></script><script src="/UEval/_next/static/chunks/2814-7a47901a8df8142e.js" async=""></script><script src="/UEval/_next/static/chunks/app/(home)/layout-5a237f94e77629d3.js" async=""></script><script src="/UEval/_next/static/chunks/5965-186e4c3e189a57da.js" async=""></script><script src="/UEval/_next/static/chunks/5580-c6313e80a056744b.js" async=""></script><script src="/UEval/_next/static/chunks/9065-79c6eac424f842ad.js" async=""></script><script src="/UEval/_next/static/chunks/4522-a272cb4d9f4960d9.js" async=""></script><script src="/UEval/_next/static/chunks/9326-99951e5e03ca56cd.js" async=""></script><script src="/UEval/_next/static/chunks/app/(home)/news/%5Bslug%5D/page-306decc06d173de2.js" async=""></script><meta name="next-size-adjust" content=""/><title>Introducing the Terminal-Bench Dataset Registry with SWE-Bench Verified, AppWorld, DevEval, and EvoEval</title><meta name="description" content="An easy way to evaluate agents on popular benchmarks and distribute new benchmarks to agent developers."/><meta property="og:title" content="UEval: A Benchmark for Unified Multimodal Generation"/><meta property="og:description" content="UEval is a challenging real-world benchmark for multimodal generation of unified models that are capable of generating both images and text."/><meta property="og:url" content="http://localhost:3000/UEval"/><meta property="og:site_name" content="UEval"/><meta property="og:locale" content="en_US"/><meta property="og:image" content="http://localhost:3000/UEval/UEval/og.png"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="UEval: A Benchmark for Unified Multimodal Generation"/><meta name="twitter:description" content="UEval is a challenging real-world benchmark for multimodal generation of unified models that are capable of generating both images and text."/><meta name="twitter:image" content="http://localhost:3000/UEval/UEval/og.png"/><meta name="twitter:image:width" content="1200"/><meta name="twitter:image:height" content="630"/><link rel="icon" href="/favicon.ico"/><script src="/UEval/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="flex min-h-screen flex-col"><div hidden=""><!--$--><!--/$--></div><script>((a,b,c,d,e,f,g,h)=>{let i=document.documentElement,j=["light","dark"];function k(b){var c;(Array.isArray(a)?a:[a]).forEach(a=>{let c="class"===a,d=c&&f?e.map(a=>f[a]||a):e;c?(i.classList.remove(...d),i.classList.add(f&&f[b]?f[b]:b)):i.setAttribute(a,b)}),c=b,h&&j.includes(c)&&(i.style.colorScheme=c)}if(d)k(d);else try{let a=localStorage.getItem(b)||c,d=g&&"system"===a?window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light":a;k(d)}catch(a){}})("class","theme","system",null,["light","dark"],null,true,true)</script><div class="bg-fd-secondary/50 p-3 empty:hidden"></div><main id="nd-home-layout" class="flex flex-1 flex-col pt-14"><header id="nd-nav" class="fixed top-(--fd-banner-height) z-40 left-0 backdrop-blur-lg border-b transition-colors *:mx-auto *:max-w-fd-container bg-fd-background/80" style="right:var(--removed-body-scroll-bar-size, 0px)" aria-label="Main" data-orientation="horizontal" dir="ltr"><div style="position:relative"><nav data-orientation="horizontal" class="flex h-14 w-full items-center px-4" dir="ltr"><a class="inline-flex items-center gap-2.5 font-semibold" href="/UEval"><div class="flex items-center gap-2"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-image size-4" aria-hidden="true"><rect width="18" height="18" x="3" y="3" rx="2" ry="2"></rect><circle cx="9" cy="9" r="2"></circle><path d="m21 15-3.086-3.086a2 2 0 0 0-2.828 0L6 21"></path></svg><p class="font-mono text-base font-medium tracking-tight">UEval</p></div></a><ul class="flex flex-row items-center gap-2 px-6 max-sm:hidden"><li class="list-none"><a class="inline-flex items-center gap-1 p-2 text-fd-muted-foreground transition-colors hover:text-fd-accent-foreground data-[active=true]:text-fd-primary [&amp;_svg]:size-4 text-sm" data-active="false" data-radix-collection-item="" href="/UEval/leaderboard">Leaderboard</a></li></ul><div class="flex flex-row items-center justify-end gap-1.5 flex-1"><div class="inline-flex items-center rounded-full border p-1 max-lg:hidden" data-theme-toggle=""><button aria-label="light" class="size-6.5 rounded-full p-1.5 text-fd-muted-foreground"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-full"><circle cx="12" cy="12" r="4"></circle><path d="M12 2v2"></path><path d="M12 20v2"></path><path d="m4.93 4.93 1.41 1.41"></path><path d="m17.66 17.66 1.41 1.41"></path><path d="M2 12h2"></path><path d="M20 12h2"></path><path d="m6.34 17.66-1.41 1.41"></path><path d="m19.07 4.93-1.41 1.41"></path></svg></button><button aria-label="dark" class="size-6.5 rounded-full p-1.5 text-fd-muted-foreground"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-full"><path d="M12 3a6 6 0 0 0 9 9 9 9 0 1 1-9-9Z"></path></svg></button><button aria-label="system" class="size-6.5 rounded-full p-1.5 text-fd-muted-foreground"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-full"><path d="M5 17H4a2 2 0 0 1-2-2V5a2 2 0 0 1 2-2h16a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-1"></path><path d="m12 15 5 6H7Z"></path></svg></button></div></div><ul class="flex flex-row items-center"><li class="list-none lg:hidden"><button id="radix-_R_35ujb_-trigger-radix-_R_1ar5ujb_" data-state="closed" aria-expanded="false" aria-controls="radix-_R_35ujb_-content-radix-_R_1ar5ujb_" class="data-[state=open]:bg-fd-accent/50 inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none hover:bg-fd-accent hover:text-fd-accent-foreground p-1.5 [&amp;_svg]:size-5 group -me-1.5" aria-label="Toggle Menu" data-radix-collection-item=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide !size-5.5 transition-transform duration-300 group-data-[state=open]:rotate-180"><path d="m6 9 6 6 6-6"></path></svg></button></li></ul></nav></div><div class="flex w-full justify-center"></div></header><div class="flex flex-1 flex-col items-center px-4"><div class="flex w-full max-w-4xl flex-1 flex-col"><div class="flex-1 pt-6 sm:pt-12"><div class="mb-6 flex items-center justify-between gap-2"><p class="text-fd-muted-foreground font-mono text-sm">Tue Jul 15 2025<!-- --> • <!-- -->Release</p><button data-slot="button" class="inline-flex items-center justify-center gap-2 whitespace-nowrap text-sm transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*=&#x27;size-&#x27;])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive hover:bg-accent hover:text-accent-foreground dark:hover:bg-accent/50 h-9 px-4 py-2 has-[&gt;svg]:px-3 rounded-none font-mono font-normal"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link h-4 w-4" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg><span>Share</span></button></div><h1 class="mb-8 font-mono text-4xl/normal font-medium tracking-tight">Introducing the Terminal-Bench Dataset Registry with SWE-Bench Verified, AppWorld, DevEval, and EvoEval</h1><p class="text-fd-muted-foreground font-mono">An easy way to evaluate agents on popular benchmarks and distribute new benchmarks to agent developers.</p></div><article class="flex w-full flex-col py-8"><div class="prose min-w-0"><p>Today we’re announcing the Terminal-Bench registry: an easy way to evaluate agents on many agentic benchmarks via the Terminal-Bench framework. For benchmark developers, the Terminal-Bench registry also offers a way to distribute benchmarks to agent developers and run existing agents in a unified way.</p>
<p>Terminal-Bench-Core, our benchmark for evaluating agents in the command line, provides a comprehensive testbed for measuring agents on software engineering, scientific computing, system administration, and more. But benchmarks from other researchers, like SWE-Bench, AppWorld, DevEval, etc. help paint a broader picture of agent performance on specific domains.</p>
<p>Until now, evaluating agents on multiple benchmarks has been difficult and time-consuming. Each benchmark comes with its own repository, evaluation harness, dependencies, and Docker images. Testing a new agent or model means cloning each of these repositories and spending hours or days familiarizing yourself with the project&#x27;s structure and getting it to run.</p>
<p>The Terminal-Bench registry solves this problem. Benchmark developers can now build new benchmarks using—or adapt existing ones to use—the Terminal-Bench harness, which provides logging, live streaming, popular agent integrations, parallelization, distribution via Terminal-Bench CLI, and, coming soon, cloud hosting out of the box.</p>
<p>To supplement the launch of the Terminal-Bench registry, we’ve adapted four popular benchmarks into the Terminal-Bench framework and registered them on the Terminal-Bench registry.</p>
<div class="relative overflow-auto prose-no-margin my-6"><table><thead><tr><th>Benchmark</th><th>Description</th></tr></thead><tbody><tr><td><a href="https://www.swebench.com/" rel="noreferrer noopener" target="_blank"><strong>SWE-Bench Verified</strong></a></td><td>A well-known benchmark for evaluating LLMs on real-world software issues collected from GitHub. Given a codebase and an issue, a language model is tasked with generating a patch that resolves the described problem.</td></tr><tr><td><a href="https://appworld.dev/" rel="noreferrer noopener" target="_blank"><strong>AppWorld</strong></a></td><td>A suite of natural, diverse, and challenging autonomous agent tasks requiring rich and interactive code generation. It focuses on practical, multi-step operations that require interaction with various tools and APIs to achieve a goal.</td></tr><tr><td><a href="https://arxiv.org/abs/2405.19856" rel="noreferrer noopener" target="_blank"><strong>DevEval</strong></a></td><td>A benchmark designed to evaluate LLMs across various stages of the repo-level software development lifecycle, including software design, environment setup, implementation, acceptance testing, and unit testing.</td></tr><tr><td><a href="https://evo-eval.github.io/" rel="noreferrer noopener" target="_blank"><strong>EvoEval</strong></a></td><td>&quot;A program synthesis benchmark suite created by evolving existing benchmarks into different targeted domains for a comprehensive evaluation of LLM coding abilities.&quot;</td></tr></tbody></table></div>
<p>The Terminal-Bench registry enables agent developers to integrate their agent into Terminal-Bench once and immediately start evaluating their agent on registered evals or even start building their own set of domain-specific in-house evals.</p>
<p>To view the dataset registry, run</p>
<figure dir="ltr" class="my-4 rounded-xl bg-fd-card p-1 shiki relative border outline-none not-prose overflow-hidden text-sm shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e" tabindex="0"><div class="empty:hidden absolute top-1 right-1 z-2 bg-fd-card rounded-bl-lg border-l border-b text-fd-muted-foreground"><button type="button" class="inline-flex items-center justify-center rounded-md p-2 text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none hover:bg-fd-accent hover:text-fd-accent-foreground [&amp;_svg]:size-3.5" aria-label="Copy Text"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></div><div class="bg-fd-secondary rounded-lg border text-[13px] py-3.5 overflow-auto max-h-[600px] fd-scroll-container" style="--padding-right:calc(var(--spacing) * 8)"><pre class="min-w-full w-max *:flex *:flex-col"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0">tb</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF"> datasets</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF"> list</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D"> # Make sure to pip install terminal-bench first</span></span></code></pre></div></figure>
<p>Then, for example, to run <code>django__django-13658</code> from SWE-Bench Verified with Terminus and Claude 4 Sonnet, run</p>
<figure dir="ltr" class="my-4 rounded-xl bg-fd-card p-1 shiki relative border outline-none not-prose overflow-hidden text-sm shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e" tabindex="0"><div class="empty:hidden absolute top-1 right-1 z-2 bg-fd-card rounded-bl-lg border-l border-b text-fd-muted-foreground"><button type="button" class="inline-flex items-center justify-center rounded-md p-2 text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none hover:bg-fd-accent hover:text-fd-accent-foreground [&amp;_svg]:size-3.5" aria-label="Copy Text"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide"><rect width="14" height="14" x="8" y="8" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></div><div class="bg-fd-secondary rounded-lg border text-[13px] py-3.5 overflow-auto max-h-[600px] fd-scroll-container" style="--padding-right:calc(var(--spacing) * 8)"><pre class="min-w-full w-max *:flex *:flex-col"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0">tb</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF"> run</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF"> \\</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF">  --dataset</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF"> swebench-verified</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF"> \\</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF">  --task-id</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF"> django__django-13658</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF"> \\</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF">  --agent</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF"> terminus</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF"> \\</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF">  --model</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF"> anthropic/claude-sonnet-4-20250514</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8">  </span></span></code></pre></div></figure>
<p>which produces the following run.</p>
<!-- -->
<!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><!--/$-->
<p>We plan to regularly add more adapters for frontier benchmarks (suggestions are welcome!) and encourage the community to take advantage of the registry to develop and distribute new benchmarks.</p>
<h2 class="flex scroll-m-28 flex-row items-center gap-2" id="validating-benchmark-adaptations"><a data-card="" href="#validating-benchmark-adaptations" class="peer">Validating Benchmark Adaptations</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<p>Terminal-Bench adapters restructure existing benchmarks to use the Terminal-Bench task framework but do not alter the task contents. From the agent&#x27;s perspective, a task in the adapted benchmark is the same instruction and environment and completing the task is determined by the same set of unit tests.</p>
<p>To ensure each benchmark has been adapted correctly, we run parity experiments using the benchmark&#x27;s harness and the Terminal-Bench harness with the same agent, prompt, and model.</p>
<p>Terminal-Bench adapter resolved rates are comparable to those of the original benchmarks:</p>
<div class="relative overflow-auto prose-no-margin my-6"><table><thead><tr><th>Agent</th><th>Model</th><th>Original SWE-Bench Grading Script*</th><th>Terminal-Bench Adapter</th></tr></thead><tbody><tr><td>Terminus</td><td><code>claude-4-opus</code></td><td>66%</td><td>66%</td></tr></tbody></table></div>
<div class="relative overflow-auto prose-no-margin my-6"><table><thead><tr><th>Agent</th><th>Model</th><th>Original AppWorld**</th><th>Terminal-Bench Adapter</th></tr></thead><tbody><tr><td>Claude Code</td><td><code>claude-4-opus</code></td><td>52.1% ± 1.8%</td><td>52.1% ± 1.8%</td></tr></tbody></table></div>
<div class="relative overflow-auto prose-no-margin my-6"><table><thead><tr><th>Agent</th><th>Model</th><th>Original DevEval</th><th>Terminal-Bench Adapter</th></tr></thead><tbody><tr><td>Claude Code</td><td><code>claude-4-opus</code></td><td>22.8% ± 4.3%</td><td>21.6% ± 3.3%</td></tr><tr><td>Codex</td><td><code>o4-mini</code></td><td>22.4% ± 4.4%</td><td>23.6% ± 2.3%</td></tr></tbody></table></div>
<div class="relative overflow-auto prose-no-margin my-6"><table><thead><tr><th>Agent</th><th>Model</th><th>Original EvoEval</th><th>Terminal-Bench Adapter</th></tr></thead><tbody><tr><td>Claude Code</td><td><code>claude-4-opus</code></td><td>65.8% ± 1.7%</td><td>66.4% ± 1.4%</td></tr><tr><td>Codex</td><td><code>o4-mini</code></td><td>67.1% ± 1.1%</td><td>66.4% ± 2.0%</td></tr></tbody></table></div>
<p>Terminal-Bench will continue to require parity experiments for adapted benchmarks so agent developers can evaluate on the benchmarks using the Terminal-Bench harness with full confidence.</p>
<p>*Note that when SWE-bench was released, the task was to generate a patch file given context from the repo in a single model call. There is no first-party evaluation harness, but rather a script to grade patch files. To ensure our adaptation is correct, we ran Terminus using the Terminal-Bench harness, extracted the patches, and evaluated them using the SWE-bench grading script, which produced the same results as our harness.</p>
<p>** Post-publication AppWorld released a CLI for terminal-based agents to interact with the environment. With the support of the AppWorld authors, we extracted agent actions on this CLI from our harness runs and evaluated them using the original AppWorld grading script, which produced the same results as our harness.</p>
<h2 class="flex scroll-m-28 flex-row items-center gap-2" id="for-benchmark-developers"><a data-card="" href="#for-benchmark-developers" class="peer">For Benchmark Developers</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<p>The Terminal-Bench framework supports text-based agent benchmarks that can be represented as an instruction, docker environment, and test script.</p>
<p>Interested in making it easier for users to run your benchmark? Consider <a href="/UEval/docs/adapters">building an adapter</a>.</p>
<p>Building a new benchmark? Use the Terminal-Bench framework to build (<code>tb tasks create</code>), quality check (<code>tb tasks check</code>), run (<code>tb run</code>), and register your benchmark to take advantage of the harness and logging infra so you can focus on building tasks and running experiments.</p>
<h2 class="flex scroll-m-28 flex-row items-center gap-2" id="planned-adapters"><a data-card="" href="#planned-adapters" class="peer">Planned Adapters</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100" aria-label="Link to section"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<p>We plan to adapt the following benchmarks into the Terminal-Bench framework: MLE-Bench, SWE-Lancer, RE-Bench, BIX-Bench, The Agent Company, Research Bench, Cybench, and AlgoTune.</p>
<p>If you have a Terminal-Bench compatible benchmark you&#x27;d like to see adapted, please <a href="https://github.com/laude-institute/terminal-bench/issues/new" rel="noreferrer noopener" target="_blank">open an issue</a> or let us know on <a href="https://discord.gg/6xWPKhGDbA" rel="noreferrer noopener" target="_blank">Discord</a>.</p></div><div class="mt-12 flex flex-col gap-4 text-sm"><div><p class="text-fd-muted-foreground mb-1 font-mono">Written by</p><p class="font-mono"><span><a class="underline-offset-4 hover:underline">The Terminal-Bench Team</a></span></p></div></div></article></div></div><!--$--><!--/$--></main><section aria-label="Notifications alt+T" tabindex="-1" aria-live="polite" aria-relevant="additions text" aria-atomic="false"></section><script src="/UEval/_next/static/chunks/webpack-a09365ebe8d26123.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[60729,[\"2619\",\"static/chunks/2619-6e4b0f7a5e306a67.js\",\"8720\",\"static/chunks/8720-84a9ef373a7f70f3.js\",\"3131\",\"static/chunks/3131-b09b0f545be46bfd.js\",\"7177\",\"static/chunks/app/layout-1cb9fbcc639ea8d3.js\"],\"RootProvider\"]\n3:I[76454,[\"2619\",\"static/chunks/2619-6e4b0f7a5e306a67.js\",\"8720\",\"static/chunks/8720-84a9ef373a7f70f3.js\",\"3131\",\"static/chunks/3131-b09b0f545be46bfd.js\",\"7177\",\"static/chunks/app/layout-1cb9fbcc639ea8d3.js\"],\"NuqsAdapter\"]\n4:I[9766,[],\"\"]\n5:I[49567,[\"5707\",\"static/chunks/5707-3ed4755c3efe5d6d.js\",\"8039\",\"static/chunks/app/error-ae7bc8cfe55bb9bb.js\"],\"default\"]\n6:I[98924,[],\"\"]\n7:I[70240,[\"2619\",\"static/chunks/2619-6e4b0f7a5e306a67.js\",\"8720\",\"static/chunks/8720-84a9ef373a7f70f3.js\",\"3131\",\"static/chunks/3131-b09b0f545be46bfd.js\",\"7177\",\"static/chunks/app/layout-1cb9fbcc639ea8d3.js\"],\"Toaster\"]\n8:I[67652,[\"5707\",\"static/chunks/5707-3ed4755c3efe5d6d.js\",\"2906\",\"static/chunks/2906-d3accac85286ef3a.js\",\"4127\",\"static/chunks/4127-d7e3f6c805caa2e3.js\",\"7712\",\"static/chunks/7712-4cbad2349309b180.js\",\"2659\",\"static/chunks/2659-581a7e9225987806.js\",\"2814\",\"static/chunks/2814-7a47901a8df8142e.js\",\"4790\",\"static/chunks/app/(home)/layout-5a237f94e77629d3.js\"],\"NavProvider\"]\n9:I[32465,[\"5707\",\"static/chunks/5707-3ed4755c3efe5d6d.js\",\"2906\",\"static/chunks/2906-d3accac85286ef3a.js\",\"4127\",\"static/chunks/4127-d7e3f6c805caa2e3.js\",\"7712\",\"static/chunks/7712-4cbad2349309b180.js\",\"2659\",\"static/chunks/2659-581a7e9225987806.js\",\"2814\",\"static/chunks/2814-7a47901a8df8142e.js\",\"4790\",\"static/chunks/app/(home)/layout-5a237f94e77629d3.js\"],\"Navbar\"]\na:I[1481,[\"5707\",\"static/chunks/5707-3ed4755c3efe5d6d.js\",\"2619\",\"static/chunks/2619-6e4b0f7a5e306a67.js\",\"2906\",\"static/chunks/2906-d3accac85286ef3a.js\",\"4127\",\"static/chunks/4127-d7e3f6c805caa2e3.js\",\"7712\",\"static/chunks/7712-4cbad2349309b180.js\",\"2659\",\"static/chunks/2659-581a7e9225987806.js\",\"5965\",\"static/chunks/5965-186e4c3e189a57da.js\",\"8720\",\"static/chunks/8720-84a9ef373a7f70f3.js\",\"5580\",\"static/chunks/5580-c6313e80a056744b.js\",\"9065\",\"s"])</script><script>self.__next_f.push([1,"tatic/chunks/9065-79c6eac424f842ad.js\",\"4522\",\"static/chunks/4522-a272cb4d9f4960d9.js\",\"9326\",\"static/chunks/9326-99951e5e03ca56cd.js\",\"1387\",\"static/chunks/app/(home)/news/%5Bslug%5D/page-306decc06d173de2.js\"],\"default\"]\nb:I[32465,[\"5707\",\"static/chunks/5707-3ed4755c3efe5d6d.js\",\"2906\",\"static/chunks/2906-d3accac85286ef3a.js\",\"4127\",\"static/chunks/4127-d7e3f6c805caa2e3.js\",\"7712\",\"static/chunks/7712-4cbad2349309b180.js\",\"2659\",\"static/chunks/2659-581a7e9225987806.js\",\"2814\",\"static/chunks/2814-7a47901a8df8142e.js\",\"4790\",\"static/chunks/app/(home)/layout-5a237f94e77629d3.js\"],\"NavbarLink\"]\nc:I[49557,[\"5707\",\"static/chunks/5707-3ed4755c3efe5d6d.js\",\"2906\",\"static/chunks/2906-d3accac85286ef3a.js\",\"4127\",\"static/chunks/4127-d7e3f6c805caa2e3.js\",\"7712\",\"static/chunks/7712-4cbad2349309b180.js\",\"2659\",\"static/chunks/2659-581a7e9225987806.js\",\"2814\",\"static/chunks/2814-7a47901a8df8142e.js\",\"4790\",\"static/chunks/app/(home)/layout-5a237f94e77629d3.js\"],\"ThemeToggle\"]\nd:I[20356,[\"5707\",\"static/chunks/5707-3ed4755c3efe5d6d.js\",\"2906\",\"static/chunks/2906-d3accac85286ef3a.js\",\"4127\",\"static/chunks/4127-d7e3f6c805caa2e3.js\",\"7712\",\"static/chunks/7712-4cbad2349309b180.js\",\"2659\",\"static/chunks/2659-581a7e9225987806.js\",\"2814\",\"static/chunks/2814-7a47901a8df8142e.js\",\"4790\",\"static/chunks/app/(home)/layout-5a237f94e77629d3.js\"],\"Menu\"]\ne:I[20356,[\"5707\",\"static/chunks/5707-3ed4755c3efe5d6d.js\",\"2906\",\"static/chunks/2906-d3accac85286ef3a.js\",\"4127\",\"static/chunks/4127-d7e3f6c805caa2e3.js\",\"7712\",\"static/chunks/7712-4cbad2349309b180.js\",\"2659\",\"static/chunks/2659-581a7e9225987806.js\",\"2814\",\"static/chunks/2814-7a47901a8df8142e.js\",\"4790\",\"static/chunks/app/(home)/layout-5a237f94e77629d3.js\"],\"MenuTrigger\"]\nf:I[20356,[\"5707\",\"static/chunks/5707-3ed4755c3efe5d6d.js\",\"2906\",\"static/chunks/2906-d3accac85286ef3a.js\",\"4127\",\"static/chunks/4127-d7e3f6c805caa2e3.js\",\"7712\",\"static/chunks/7712-4cbad2349309b180.js\",\"2659\",\"static/chunks/2659-581a7e9225987806.js\",\"2814\",\"static/chunks/2814-7a47901a8df8142e.js\",\"4790\",\"static/chunks/app/(home"])</script><script>self.__next_f.push([1,")/layout-5a237f94e77629d3.js\"],\"MenuContent\"]\n10:I[20356,[\"5707\",\"static/chunks/5707-3ed4755c3efe5d6d.js\",\"2906\",\"static/chunks/2906-d3accac85286ef3a.js\",\"4127\",\"static/chunks/4127-d7e3f6c805caa2e3.js\",\"7712\",\"static/chunks/7712-4cbad2349309b180.js\",\"2659\",\"static/chunks/2659-581a7e9225987806.js\",\"2814\",\"static/chunks/2814-7a47901a8df8142e.js\",\"4790\",\"static/chunks/app/(home)/layout-5a237f94e77629d3.js\"],\"MenuLinkItem\"]\n17:I[57150,[],\"\"]\n:HL[\"/UEval/_next/static/media/66f30814ff6d7cdf.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/UEval/_next/static/media/e4af272ccee01ff0-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/UEval/_next/static/css/5a9dae0d910ab8e0.css\",\"style\"]\n:HL[\"/UEval/_next/static/css/f0b4f6c31c32f4c0.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"cJ2AMD_FyXA9wZjgwrnSX\",\"p\":\"/UEval\",\"c\":[\"\",\"news\",\"registry-and-adapters\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"(home)\",{\"children\":[\"news\",{\"children\":[[\"slug\",\"registry-and-adapters\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/UEval/_next/static/css/5a9dae0d910ab8e0.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"className\":\"__className_370cd6 __variable_3b6218\",\"suppressHydrationWarning\":true,\"children\":[\"$\",\"body\",null,{\"className\":\"flex min-h-screen flex-col\",\"children\":[[\"$\",\"$L2\",null,{\"children\":[\"$\",\"$L3\",null,{\"children\":[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$5\",\"errorStyles\":[],\"errorScripts\":[],\"template\":[\"$\",\"$L6\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}],[\"$\",\"$L7\",null,{}]]}]}]]}],{\"children\":[\"(home)\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L8\",null,{\"transparentMode\":\"$undefined\",\"children\":[\"$\",\"main\",null,{\"id\":\"nd-home-layout\",\"children\":[[\"$\",\"$L9\",null,{\"children\":[[\"$\",\"$La\",null,{\"href\":\"/\",\"className\":\"inline-flex items-center gap-2.5 font-semibold\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex items-center gap-2\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-image size-4\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"rect\",\"1m3agn\",{\"width\":\"18\",\"height\":\"18\",\"x\":\"3\",\"y\":\"3\",\"rx\":\"2\",\"ry\":\"2\"}],[\"$\",\"circle\",\"af1f0g\",{\"cx\":\"9\",\"cy\":\"9\",\"r\":\"2\"}],[\"$\",\"path\",\"1xmnt7\",{\"d\":\"m21 15-3.086-3.086a2 2 0 0 0-2.828 0L6 21\"}],\"$undefined\"]}],[\"$\",\"p\",null,{\"className\":\"font-mono text-base font-medium tracking-tight\",\"children\":\"UEval\"}]]}]}],\"$undefined\",[\"$\",\"ul\",null,{\"className\":\"flex flex-row items-center gap-2 px-6 max-sm:hidden\",\"children\":[[\"$\",\"$Lb\",\"0\",{\"className\":\"text-sm\",\"item\":{\"text\":\"Leaderboard\",\"url\":\"/leaderboard\",\"active\":\"nested-url\"},\"variant\":\"$undefined\",\"aria-label\":\"$undefined\",\"children\":\"Leaderboard\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex flex-row items-center justify-end gap-1.5 flex-1\",\"children\":[false,[\"$\",\"$Lc\",null,{\"className\":\"max-lg:hidden\",\"mode\":\"light-dark-system\"}],null]}],[\"$\",\"ul\",null,{\"className\":\"flex flex-row items-center\",\"children\":[[],[\"$\",\"$Ld\",null,{\"className\":\"lg:hidden\",\"children\":[[\"$\",\"$Le\",null,{\"aria-label\":\"Toggle Menu\",\"className\":\"inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors duration-100 disabled:pointer-events-none disabled:opacity-50 focus-visible:outline-none hover:bg-fd-accent hover:text-fd-accent-foreground p-1.5 [\u0026_svg]:size-5 group -me-1.5\",\"enableHover\":\"$undefined\",\"children\":[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide !size-5.5 transition-transform duration-300 group-data-[state=open]:rotate-180\",\"children\":[[[\"$\",\"path\",\"qrunsl\",{\"d\":\"m6 9 6 6 6-6\"}]],\"$undefined\"]}]}],[\"$\",\"$Lf\",null,{\"className\":\"sm:flex-row sm:items-center sm:justify-end\",\"children\":[[[\"$\",\"$L10\",\"0\",{\"item\":\"$0:f:0:1:2:children:1:props:children:1:props:children:props:children:0:props:children:2:props:children:0:props:item\",\"className\":\"sm:hidden\"}]],[\"$\",\"div\",null,{\"className\":\"-ms-1.5 flex flex-row items-center gap-1.5 max-sm:mt-2\",\"children\":[[],[\"$\",\"div\",null,{\"role\":\"separator\",\"className\":\"flex-1\"}],null,\"$L11\"]}]]}]]}]]}]]}],\"$L12\"],\"className\":\"flex flex-1 flex-col pt-14\"}]}]]}],{\"children\":[\"news\",\"$L13\",{\"children\":[[\"slug\",\"registry-and-adapters\",\"d\"],\"$L14\",{\"children\":[\"__PAGE__\",\"$L15\",{},null,false]},null,false]},null,false]},null,false]},null,false],\"$L16\",false]],\"m\":\"$undefined\",\"G\":[\"$17\",[]],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"19:I[24431,[],\"OutletBoundary\"]\n1b:I[15278,[],\"AsyncMetadataOutlet\"]\n1d:I[24431,[],\"ViewportBoundary\"]\n1f:I[24431,[],\"MetadataBoundary\"]\n20:\"$Sreact.suspense\"\n11:[\"$\",\"$Lc\",null,{\"mode\":\"light-dark-system\"}]\n"])</script><script>self.__next_f.push([1,"12:[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L6\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":\"$0:f:0:1:1:props:children:1:props:children:props:children:0:props:children:props:children:props:notFound:0:1:props:style\",\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":\"$0:f:0:1:1:props:children:1:props:children:props:children:0:props:children:props:children:props:notFound:0:1:props:children:props:children:1:props:style\",\"children\":404}],[\"$\",\"div\",null,{\"style\":\"$0:f:0:1:1:props:children:1:props:children:props:children:0:props:children:props:children:props:notFound:0:1:props:children:props:children:2:props:style\",\"children\":[\"$\",\"h2\",null,{\"style\":\"$0:f:0:1:1:props:children:1:props:children:props:children:0:props:children:props:children:props:notFound:0:1:props:children:props:children:2:props:children:props:style\",\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]\n"])</script><script>self.__next_f.push([1,"13:[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L6\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}]\n14:[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L6\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}]\n15:[\"$\",\"$1\",\"c\",{\"children\":[\"$L18\",[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/UEval/_next/static/css/f0b4f6c31c32f4c0.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"$L19\",null,{\"children\":[\"$L1a\",[\"$\",\"$L1b\",null,{\"promise\":\"$@1c\"}]]}]]}]\n16:[\"$\",\"$1\",\"h\",{\"children\":[null,[[\"$\",\"$L1d\",null,{\"children\":\"$L1e\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]],[\"$\",\"$L1f\",null,{\"children\":[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$20\",null,{\"fallback\":null,\"children\":\"$L21\"}]}]}]]}]\n"])</script><script>self.__next_f.push([1,"22:I[7656,[\"5707\",\"static/chunks/5707-3ed4755c3efe5d6d.js\",\"2619\",\"static/chunks/2619-6e4b0f7a5e306a67.js\",\"2906\",\"static/chunks/2906-d3accac85286ef3a.js\",\"4127\",\"static/chunks/4127-d7e3f6c805caa2e3.js\",\"7712\",\"static/chunks/7712-4cbad2349309b180.js\",\"2659\",\"static/chunks/2659-581a7e9225987806.js\",\"5965\",\"static/chunks/5965-186e4c3e189a57da.js\",\"8720\",\"static/chunks/8720-84a9ef373a7f70f3.js\",\"5580\",\"static/chunks/5580-c6313e80a056744b.js\",\"9065\",\"static/chunks/9065-79c6eac424f842ad.js\",\"4522\",\"static/chunks/4522-a272cb4d9f4960d9.js\",\"9326\",\"static/chunks/9326-99951e5e03ca56cd.js\",\"1387\",\"static/chunks/app/(home)/news/%5Bslug%5D/page-306decc06d173de2.js\"],\"Share\"]\n"])</script><script>self.__next_f.push([1,"18:[\"$\",\"div\",null,{\"className\":\"flex flex-1 flex-col items-center px-4\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex w-full max-w-4xl flex-1 flex-col\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex-1 pt-6 sm:pt-12\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-6 flex items-center justify-between gap-2\",\"children\":[[\"$\",\"p\",null,{\"className\":\"text-fd-muted-foreground font-mono text-sm\",\"children\":[\"Tue Jul 15 2025\",\" • \",\"Release\"]}],[\"$\",\"$L22\",null,{}]]}],[\"$\",\"h1\",null,{\"className\":\"mb-8 font-mono text-4xl/normal font-medium tracking-tight\",\"children\":\"Introducing the Terminal-Bench Dataset Registry with SWE-Bench Verified, AppWorld, DevEval, and EvoEval\"}],[\"$\",\"p\",null,{\"className\":\"text-fd-muted-foreground font-mono\",\"children\":\"An easy way to evaluate agents on popular benchmarks and distribute new benchmarks to agent developers.\"}],false]}],[\"$\",\"article\",null,{\"className\":\"flex w-full flex-col py-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"prose min-w-0\",\"children\":[[\"$\",\"p\",null,{\"children\":\"Today we’re announcing the Terminal-Bench registry: an easy way to evaluate agents on many agentic benchmarks via the Terminal-Bench framework. For benchmark developers, the Terminal-Bench registry also offers a way to distribute benchmarks to agent developers and run existing agents in a unified way.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Terminal-Bench-Core, our benchmark for evaluating agents in the command line, provides a comprehensive testbed for measuring agents on software engineering, scientific computing, system administration, and more. But benchmarks from other researchers, like SWE-Bench, AppWorld, DevEval, etc. help paint a broader picture of agent performance on specific domains.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Until now, evaluating agents on multiple benchmarks has been difficult and time-consuming. Each benchmark comes with its own repository, evaluation harness, dependencies, and Docker images. Testing a new agent or model means cloning each of these repositories and spending hours or days familiarizing yourself with the project's structure and getting it to run.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"The Terminal-Bench registry solves this problem. Benchmark developers can now build new benchmarks using—or adapt existing ones to use—the Terminal-Bench harness, which provides logging, live streaming, popular agent integrations, parallelization, distribution via Terminal-Bench CLI, and, coming soon, cloud hosting out of the box.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"To supplement the launch of the Terminal-Bench registry, we’ve adapted four popular benchmarks into the Terminal-Bench framework and registered them on the Terminal-Bench registry.\"}],\"\\n\",[\"$\",\"div\",null,{\"className\":\"relative overflow-auto prose-no-margin my-6\",\"children\":[\"$\",\"table\",null,{\"children\":[[\"$\",\"thead\",null,{\"children\":[\"$\",\"tr\",null,{\"children\":[[\"$\",\"th\",null,{\"children\":\"Benchmark\"}],[\"$\",\"th\",null,{\"children\":\"Description\"}]]}]}],[\"$\",\"tbody\",null,{\"children\":[[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"$La\",null,{\"href\":\"https://www.swebench.com/\",\"children\":[\"$\",\"strong\",null,{\"children\":\"SWE-Bench Verified\"}]}]}],[\"$\",\"td\",null,{\"children\":\"A well-known benchmark for evaluating LLMs on real-world software issues collected from GitHub. Given a codebase and an issue, a language model is tasked with generating a patch that resolves the described problem.\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"$La\",null,{\"href\":\"https://appworld.dev/\",\"children\":[\"$\",\"strong\",null,{\"children\":\"AppWorld\"}]}]}],[\"$\",\"td\",null,{\"children\":\"A suite of natural, diverse, and challenging autonomous agent tasks requiring rich and interactive code generation. It focuses on practical, multi-step operations that require interaction with various tools and APIs to achieve a goal.\"}]]}],\"$L23\",\"$L24\"]}]]}]}],\"\\n\",\"$L25\",\"\\n\",\"$L26\",\"\\n\",\"$L27\",\"\\n\",\"$L28\",\"\\n\",\"$L29\",\"\\n\",\"$L2a\",\"\\n\",\"\\n\",\"$L2b\",\"\\n\",\"$L2c\",\"\\n\",\"$L2d\",\"\\n\",\"$L2e\",\"\\n\",\"$L2f\",\"\\n\",\"$L30\",\"\\n\",\"$L31\",\"\\n\",\"$L32\",\"\\n\",\"$L33\",\"\\n\",\"$L34\",\"\\n\",\"$L35\",\"\\n\",\"$L36\",\"\\n\",\"$L37\",\"\\n\",\"$L38\",\"\\n\",\"$L39\",\"\\n\",\"$L3a\",\"\\n\",\"$L3b\",\"\\n\",\"$L3c\",\"\\n\",\"$L3d\",\"\\n\",\"$L3e\"]}],\"$L3f\"]}]]}]}]\n"])</script><script>self.__next_f.push([1,"40:I[75580,[\"5707\",\"static/chunks/5707-3ed4755c3efe5d6d.js\",\"2619\",\"static/chunks/2619-6e4b0f7a5e306a67.js\",\"2906\",\"static/chunks/2906-d3accac85286ef3a.js\",\"4127\",\"static/chunks/4127-d7e3f6c805caa2e3.js\",\"7712\",\"static/chunks/7712-4cbad2349309b180.js\",\"2659\",\"static/chunks/2659-581a7e9225987806.js\",\"5965\",\"static/chunks/5965-186e4c3e189a57da.js\",\"8720\",\"static/chunks/8720-84a9ef373a7f70f3.js\",\"5580\",\"static/chunks/5580-c6313e80a056744b.js\",\"9065\",\"static/chunks/9065-79c6eac424f842ad.js\",\"4522\",\"static/chunks/4522-a272cb4d9f4960d9.js\",\"9326\",\"static/chunks/9326-99951e5e03ca56cd.js\",\"1387\",\"static/chunks/app/(home)/news/%5Bslug%5D/page-306decc06d173de2.js\"],\"CodeBlock\"]\n41:I[75580,[\"5707\",\"static/chunks/5707-3ed4755c3efe5d6d.js\",\"2619\",\"static/chunks/2619-6e4b0f7a5e306a67.js\",\"2906\",\"static/chunks/2906-d3accac85286ef3a.js\",\"4127\",\"static/chunks/4127-d7e3f6c805caa2e3.js\",\"7712\",\"static/chunks/7712-4cbad2349309b180.js\",\"2659\",\"static/chunks/2659-581a7e9225987806.js\",\"5965\",\"static/chunks/5965-186e4c3e189a57da.js\",\"8720\",\"static/chunks/8720-84a9ef373a7f70f3.js\",\"5580\",\"static/chunks/5580-c6313e80a056744b.js\",\"9065\",\"static/chunks/9065-79c6eac424f842ad.js\",\"4522\",\"static/chunks/4522-a272cb4d9f4960d9.js\",\"9326\",\"static/chunks/9326-99951e5e03ca56cd.js\",\"1387\",\"static/chunks/app/(home)/news/%5Bslug%5D/page-306decc06d173de2.js\"],\"Pre\"]\n42:I[40149,[\"5707\",\"static/chunks/5707-3ed4755c3efe5d6d.js\",\"2619\",\"static/chunks/2619-6e4b0f7a5e306a67.js\",\"2906\",\"static/chunks/2906-d3accac85286ef3a.js\",\"4127\",\"static/chunks/4127-d7e3f6c805caa2e3.js\",\"7712\",\"static/chunks/7712-4cbad2349309b180.js\",\"2659\",\"static/chunks/2659-581a7e9225987806.js\",\"5965\",\"static/chunks/5965-186e4c3e189a57da.js\",\"8720\",\"static/chunks/8720-84a9ef373a7f70f3.js\",\"5580\",\"static/chunks/5580-c6313e80a056744b.js\",\"9065\",\"static/chunks/9065-79c6eac424f842ad.js\",\"4522\",\"static/chunks/4522-a272cb4d9f4960d9.js\",\"9326\",\"static/chunks/9326-99951e5e03ca56cd.js\",\"1387\",\"static/chunks/app/(home)/news/%5Bslug%5D/page-306decc06d173de2.js\"],\"default\"]\n23:[\"$\",\"tr\",null,{\"child"])</script><script>self.__next_f.push([1,"ren\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"$La\",null,{\"href\":\"https://arxiv.org/abs/2405.19856\",\"children\":[\"$\",\"strong\",null,{\"children\":\"DevEval\"}]}]}],[\"$\",\"td\",null,{\"children\":\"A benchmark designed to evaluate LLMs across various stages of the repo-level software development lifecycle, including software design, environment setup, implementation, acceptance testing, and unit testing.\"}]]}]\n24:[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":[\"$\",\"$La\",null,{\"href\":\"https://evo-eval.github.io/\",\"children\":[\"$\",\"strong\",null,{\"children\":\"EvoEval\"}]}]}],[\"$\",\"td\",null,{\"children\":\"\\\"A program synthesis benchmark suite created by evolving existing benchmarks into different targeted domains for a comprehensive evaluation of LLM coding abilities.\\\"\"}]]}]\n25:[\"$\",\"p\",null,{\"children\":\"The Terminal-Bench registry enables agent developers to integrate their agent into Terminal-Bench once and immediately start evaluating their agent on registered evals or even start building their own set of domain-specific in-house evals.\"}]\n26:[\"$\",\"p\",null,{\"children\":\"To view the dataset registry, run\"}]\n"])</script><script>self.__next_f.push([1,"27:[\"$\",\"$L40\",null,{\"className\":\"shiki shiki-themes github-light github-dark\",\"style\":{\"--shiki-light\":\"#24292e\",\"--shiki-dark\":\"#e1e4e8\",\"--shiki-light-bg\":\"#fff\",\"--shiki-dark-bg\":\"#24292e\"},\"tabIndex\":\"0\",\"icon\":\"\u003csvg viewBox=\\\"0 0 24 24\\\"\u003e\u003cpath d=\\\"m 4,4 a 1,1 0 0 0 -0.7070312,0.2929687 1,1 0 0 0 0,1.4140625 L 8.5859375,11 3.2929688,16.292969 a 1,1 0 0 0 0,1.414062 1,1 0 0 0 1.4140624,0 l 5.9999998,-6 a 1.0001,1.0001 0 0 0 0,-1.414062 L 4.7070312,4.2929687 A 1,1 0 0 0 4,4 Z m 8,14 a 1,1 0 0 0 -1,1 1,1 0 0 0 1,1 h 8 a 1,1 0 0 0 1,-1 1,1 0 0 0 -1,-1 z\\\" fill=\\\"currentColor\\\" /\u003e\u003c/svg\u003e\",\"children\":[\"$\",\"$L41\",null,{\"children\":[\"$\",\"code\",null,{\"children\":[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#6F42C1\",\"--shiki-dark\":\"#B392F0\"},\"children\":\"tb\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#032F62\",\"--shiki-dark\":\"#9ECBFF\"},\"children\":\" datasets\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#032F62\",\"--shiki-dark\":\"#9ECBFF\"},\"children\":\" list\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#6A737D\",\"--shiki-dark\":\"#6A737D\"},\"children\":\" # Make sure to pip install terminal-bench first\"}]]}]}]}]}]\n"])</script><script>self.__next_f.push([1,"28:[\"$\",\"p\",null,{\"children\":[\"Then, for example, to run \",[\"$\",\"code\",null,{\"children\":\"django__django-13658\"}],\" from SWE-Bench Verified with Terminus and Claude 4 Sonnet, run\"]}]\n"])</script><script>self.__next_f.push([1,"29:[\"$\",\"$L40\",null,{\"className\":\"shiki shiki-themes github-light github-dark\",\"style\":{\"--shiki-light\":\"#24292e\",\"--shiki-dark\":\"#e1e4e8\",\"--shiki-light-bg\":\"#fff\",\"--shiki-dark-bg\":\"#24292e\"},\"tabIndex\":\"0\",\"icon\":\"\u003csvg viewBox=\\\"0 0 24 24\\\"\u003e\u003cpath d=\\\"m 4,4 a 1,1 0 0 0 -0.7070312,0.2929687 1,1 0 0 0 0,1.4140625 L 8.5859375,11 3.2929688,16.292969 a 1,1 0 0 0 0,1.414062 1,1 0 0 0 1.4140624,0 l 5.9999998,-6 a 1.0001,1.0001 0 0 0 0,-1.414062 L 4.7070312,4.2929687 A 1,1 0 0 0 4,4 Z m 8,14 a 1,1 0 0 0 -1,1 1,1 0 0 0 1,1 h 8 a 1,1 0 0 0 1,-1 1,1 0 0 0 -1,-1 z\\\" fill=\\\"currentColor\\\" /\u003e\u003c/svg\u003e\",\"children\":[\"$\",\"$L41\",null,{\"children\":[\"$\",\"code\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#6F42C1\",\"--shiki-dark\":\"#B392F0\"},\"children\":\"tb\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#032F62\",\"--shiki-dark\":\"#9ECBFF\"},\"children\":\" run\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#005CC5\",\"--shiki-dark\":\"#79B8FF\"},\"children\":\" \\\\\\\\\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#005CC5\",\"--shiki-dark\":\"#79B8FF\"},\"children\":\"  --dataset\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#032F62\",\"--shiki-dark\":\"#9ECBFF\"},\"children\":\" swebench-verified\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#005CC5\",\"--shiki-dark\":\"#79B8FF\"},\"children\":\" \\\\\\\\\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#005CC5\",\"--shiki-dark\":\"#79B8FF\"},\"children\":\"  --task-id\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#032F62\",\"--shiki-dark\":\"#9ECBFF\"},\"children\":\" django__django-13658\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#005CC5\",\"--shiki-dark\":\"#79B8FF\"},\"children\":\" \\\\\\\\\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#005CC5\",\"--shiki-dark\":\"#79B8FF\"},\"children\":\"  --agent\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#032F62\",\"--shiki-dark\":\"#9ECBFF\"},\"children\":\" terminus\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#005CC5\",\"--shiki-dark\":\"#79B8FF\"},\"children\":\" \\\\\\\\\"}]]}],\"\\n\",[\"$\",\"span\",null,{\"className\":\"line\",\"children\":[[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#005CC5\",\"--shiki-dark\":\"#79B8FF\"},\"children\":\"  --model\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#032F62\",\"--shiki-dark\":\"#9ECBFF\"},\"children\":\" anthropic/claude-sonnet-4-20250514\"}],[\"$\",\"span\",null,{\"style\":{\"--shiki-light\":\"#24292E\",\"--shiki-dark\":\"#E1E4E8\"},\"children\":\"  \"}]]}]]}]}]}]\n"])</script><script>self.__next_f.push([1,"2a:[\"$\",\"p\",null,{\"children\":\"which produces the following run.\"}]\n2b:[\"$\",\"$L42\",null,{\"src\":\"/django__django-13658.cast\",\"theme\":\"asciinema\",\"terminalFontFamily\":\"var(--font-geist-mono)\",\"autoPlay\":true,\"loop\":false}]\n2c:[\"$\",\"p\",null,{\"children\":\"We plan to regularly add more adapters for frontier benchmarks (suggestions are welcome!) and encourage the community to take advantage of the registry to develop and distribute new benchmarks.\"}]\n"])</script><script>self.__next_f.push([1,"2d:[\"$\",\"h2\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"validating-benchmark-adaptations\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#validating-benchmark-adaptations\",\"className\":\"peer\",\"children\":\"Validating Benchmark Adaptations\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}]\n"])</script><script>self.__next_f.push([1,"2e:[\"$\",\"p\",null,{\"children\":\"Terminal-Bench adapters restructure existing benchmarks to use the Terminal-Bench task framework but do not alter the task contents. From the agent's perspective, a task in the adapted benchmark is the same instruction and environment and completing the task is determined by the same set of unit tests.\"}]\n2f:[\"$\",\"p\",null,{\"children\":\"To ensure each benchmark has been adapted correctly, we run parity experiments using the benchmark's harness and the Terminal-Bench harness with the same agent, prompt, and model.\"}]\n30:[\"$\",\"p\",null,{\"children\":\"Terminal-Bench adapter resolved rates are comparable to those of the original benchmarks:\"}]\n31:[\"$\",\"div\",null,{\"className\":\"relative overflow-auto prose-no-margin my-6\",\"children\":[\"$\",\"table\",null,{\"children\":[[\"$\",\"thead\",null,{\"children\":[\"$\",\"tr\",null,{\"children\":[[\"$\",\"th\",null,{\"children\":\"Agent\"}],[\"$\",\"th\",null,{\"children\":\"Model\"}],[\"$\",\"th\",null,{\"children\":\"Original SWE-Bench Grading Script*\"}],[\"$\",\"th\",null,{\"children\":\"Terminal-Bench Adapter\"}]]}]}],[\"$\",\"tbody\",null,{\"children\":[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"Terminus\"}],[\"$\",\"td\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"claude-4-opus\"}]}],[\"$\",\"td\",null,{\"children\":\"66%\"}],[\"$\",\"td\",null,{\"children\":\"66%\"}]]}]}]]}]}]\n32:[\"$\",\"div\",null,{\"className\":\"relative overflow-auto prose-no-margin my-6\",\"children\":[\"$\",\"table\",null,{\"children\":[[\"$\",\"thead\",null,{\"children\":[\"$\",\"tr\",null,{\"children\":[[\"$\",\"th\",null,{\"children\":\"Agent\"}],[\"$\",\"th\",null,{\"children\":\"Model\"}],[\"$\",\"th\",null,{\"children\":\"Original AppWorld**\"}],[\"$\",\"th\",null,{\"children\":\"Terminal-Bench Adapter\"}]]}]}],[\"$\",\"tbody\",null,{\"children\":[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"Claude Code\"}],[\"$\",\"td\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"claude-4-opus\"}]}],[\"$\",\"td\",null,{\"children\":\"52.1% ± 1.8%\"}],[\"$\",\"td\",null,{\"children\":\"52.1% ± 1.8%\"}]]}]}]]}]}]\n"])</script><script>self.__next_f.push([1,"33:[\"$\",\"div\",null,{\"className\":\"relative overflow-auto prose-no-margin my-6\",\"children\":[\"$\",\"table\",null,{\"children\":[[\"$\",\"thead\",null,{\"children\":[\"$\",\"tr\",null,{\"children\":[[\"$\",\"th\",null,{\"children\":\"Agent\"}],[\"$\",\"th\",null,{\"children\":\"Model\"}],[\"$\",\"th\",null,{\"children\":\"Original DevEval\"}],[\"$\",\"th\",null,{\"children\":\"Terminal-Bench Adapter\"}]]}]}],[\"$\",\"tbody\",null,{\"children\":[[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"Claude Code\"}],[\"$\",\"td\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"claude-4-opus\"}]}],[\"$\",\"td\",null,{\"children\":\"22.8% ± 4.3%\"}],[\"$\",\"td\",null,{\"children\":\"21.6% ± 3.3%\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"Codex\"}],[\"$\",\"td\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"o4-mini\"}]}],[\"$\",\"td\",null,{\"children\":\"22.4% ± 4.4%\"}],[\"$\",\"td\",null,{\"children\":\"23.6% ± 2.3%\"}]]}]]}]]}]}]\n"])</script><script>self.__next_f.push([1,"34:[\"$\",\"div\",null,{\"className\":\"relative overflow-auto prose-no-margin my-6\",\"children\":[\"$\",\"table\",null,{\"children\":[[\"$\",\"thead\",null,{\"children\":[\"$\",\"tr\",null,{\"children\":[[\"$\",\"th\",null,{\"children\":\"Agent\"}],[\"$\",\"th\",null,{\"children\":\"Model\"}],[\"$\",\"th\",null,{\"children\":\"Original EvoEval\"}],[\"$\",\"th\",null,{\"children\":\"Terminal-Bench Adapter\"}]]}]}],[\"$\",\"tbody\",null,{\"children\":[[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"Claude Code\"}],[\"$\",\"td\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"claude-4-opus\"}]}],[\"$\",\"td\",null,{\"children\":\"65.8% ± 1.7%\"}],[\"$\",\"td\",null,{\"children\":\"66.4% ± 1.4%\"}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"Codex\"}],[\"$\",\"td\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"o4-mini\"}]}],[\"$\",\"td\",null,{\"children\":\"67.1% ± 1.1%\"}],[\"$\",\"td\",null,{\"children\":\"66.4% ± 2.0%\"}]]}]]}]]}]}]\n"])</script><script>self.__next_f.push([1,"35:[\"$\",\"p\",null,{\"children\":\"Terminal-Bench will continue to require parity experiments for adapted benchmarks so agent developers can evaluate on the benchmarks using the Terminal-Bench harness with full confidence.\"}]\n36:[\"$\",\"p\",null,{\"children\":\"*Note that when SWE-bench was released, the task was to generate a patch file given context from the repo in a single model call. There is no first-party evaluation harness, but rather a script to grade patch files. To ensure our adaptation is correct, we ran Terminus using the Terminal-Bench harness, extracted the patches, and evaluated them using the SWE-bench grading script, which produced the same results as our harness.\"}]\n37:[\"$\",\"p\",null,{\"children\":\"** Post-publication AppWorld released a CLI for terminal-based agents to interact with the environment. With the support of the AppWorld authors, we extracted agent actions on this CLI from our harness runs and evaluated them using the original AppWorld grading script, which produced the same results as our harness.\"}]\n"])</script><script>self.__next_f.push([1,"38:[\"$\",\"h2\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"for-benchmark-developers\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#for-benchmark-developers\",\"className\":\"peer\",\"children\":\"For Benchmark Developers\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}]\n"])</script><script>self.__next_f.push([1,"39:[\"$\",\"p\",null,{\"children\":\"The Terminal-Bench framework supports text-based agent benchmarks that can be represented as an instruction, docker environment, and test script.\"}]\n3a:[\"$\",\"p\",null,{\"children\":[\"Interested in making it easier for users to run your benchmark? Consider \",[\"$\",\"$La\",null,{\"href\":\"/docs/adapters\",\"children\":\"building an adapter\"}],\".\"]}]\n3b:[\"$\",\"p\",null,{\"children\":[\"Building a new benchmark? Use the Terminal-Bench framework to build (\",[\"$\",\"code\",null,{\"children\":\"tb tasks create\"}],\"), quality check (\",[\"$\",\"code\",null,{\"children\":\"tb tasks check\"}],\"), run (\",[\"$\",\"code\",null,{\"children\":\"tb run\"}],\"), and register your benchmark to take advantage of the harness and logging infra so you can focus on building tasks and running experiments.\"]}]\n"])</script><script>self.__next_f.push([1,"3c:[\"$\",\"h2\",null,{\"className\":\"flex scroll-m-28 flex-row items-center gap-2\",\"id\":\"planned-adapters\",\"children\":[[\"$\",\"a\",null,{\"data-card\":\"\",\"href\":\"#planned-adapters\",\"className\":\"peer\",\"children\":\"Planned Adapters\"}],[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide size-3.5 shrink-0 text-fd-muted-foreground opacity-0 transition-opacity peer-hover:opacity-100\",\"aria-label\":\"Link to section\",\"children\":[[[\"$\",\"path\",\"1cjeqo\",{\"d\":\"M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71\"}],[\"$\",\"path\",\"19qd67\",{\"d\":\"M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71\"}]],\"$undefined\"]}]]}]\n"])</script><script>self.__next_f.push([1,"3d:[\"$\",\"p\",null,{\"children\":\"We plan to adapt the following benchmarks into the Terminal-Bench framework: MLE-Bench, SWE-Lancer, RE-Bench, BIX-Bench, The Agent Company, Research Bench, Cybench, and AlgoTune.\"}]\n3e:[\"$\",\"p\",null,{\"children\":[\"If you have a Terminal-Bench compatible benchmark you'd like to see adapted, please \",[\"$\",\"$La\",null,{\"href\":\"https://github.com/laude-institute/terminal-bench/issues/new\",\"children\":\"open an issue\"}],\" or let us know on \",[\"$\",\"$La\",null,{\"href\":\"https://discord.gg/6xWPKhGDbA\",\"children\":\"Discord\"}],\".\"]}]\n3f:[\"$\",\"div\",null,{\"className\":\"mt-12 flex flex-col gap-4 text-sm\",\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"p\",null,{\"className\":\"text-fd-muted-foreground mb-1 font-mono\",\"children\":\"Written by\"}],[\"$\",\"p\",null,{\"className\":\"font-mono\",\"children\":[[\"$\",\"span\",\"The Terminal-Bench Team\",{\"children\":[[\"$\",\"a\",null,{\"href\":\"$undefined\",\"className\":\"underline-offset-4 hover:underline\",\"children\":\"The Terminal-Bench Team\"}],false]}]]}]]}]}]\n"])</script><script>self.__next_f.push([1,"1e:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n1a:null\n"])</script><script>self.__next_f.push([1,"43:I[80622,[],\"IconMark\"]\n"])</script><script>self.__next_f.push([1,"1c:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Introducing the Terminal-Bench Dataset Registry with SWE-Bench Verified, AppWorld, DevEval, and EvoEval\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"An easy way to evaluate agents on popular benchmarks and distribute new benchmarks to agent developers.\"}],[\"$\",\"meta\",\"2\",{\"property\":\"og:title\",\"content\":\"UEval: A Benchmark for Unified Multimodal Generation\"}],[\"$\",\"meta\",\"3\",{\"property\":\"og:description\",\"content\":\"UEval is a challenging real-world benchmark for multimodal generation of unified models that are capable of generating both images and text.\"}],[\"$\",\"meta\",\"4\",{\"property\":\"og:url\",\"content\":\"http://localhost:3000/UEval\"}],[\"$\",\"meta\",\"5\",{\"property\":\"og:site_name\",\"content\":\"UEval\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:locale\",\"content\":\"en_US\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:image\",\"content\":\"http://localhost:3000/UEval/UEval/og.png\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"9\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"10\",{\"name\":\"twitter:title\",\"content\":\"UEval: A Benchmark for Unified Multimodal Generation\"}],[\"$\",\"meta\",\"11\",{\"name\":\"twitter:description\",\"content\":\"UEval is a challenging real-world benchmark for multimodal generation of unified models that are capable of generating both images and text.\"}],[\"$\",\"meta\",\"12\",{\"name\":\"twitter:image\",\"content\":\"http://localhost:3000/UEval/UEval/og.png\"}],[\"$\",\"meta\",\"13\",{\"name\":\"twitter:image:width\",\"content\":\"1200\"}],[\"$\",\"meta\",\"14\",{\"name\":\"twitter:image:height\",\"content\":\"630\"}],[\"$\",\"link\",\"15\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\"}],[\"$\",\"$L43\",\"16\",{}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"21:\"$1c:metadata\"\n"])</script></body></html>